{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df7200b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dws_1', 'dws_11', 'dws_2', 'jog_16', 'jog_9', 'sit_13', 'sit_5', 'std_14', 'std_6', 'ups_12', 'ups_3', 'ups_4', 'wlk_15', 'wlk_7', 'wlk_8']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "print(os.listdir())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcffbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dws_1', 'dws_11', 'dws_2', 'jog_16', 'jog_9', 'sit_13', 'sit_5', 'std_14', 'std_6', 'ups_12', 'ups_3', 'ups_4', 'wlk_15', 'wlk_7', 'wlk_8']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "base_path = r\"C:\\Users\\Hp\\Downloads\\archive (1)\\A_DeviceMotion_data\\A_DeviceMotion_data\"  \n",
    "print(os.listdir(base_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394a6f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0                   1                    2                   3  \\\n",
      "0  NaN       attitude.roll       attitude.pitch        attitude.yaw   \n",
      "1  0.0            1.528132            -0.733896            0.696372   \n",
      "2  1.0            1.527992            -0.716987            0.677762   \n",
      "3  2.0            1.527765  -0.7069989999999999  0.6709510000000001   \n",
      "4  3.0  1.5167680000000001            -0.704678  0.6757350000000001   \n",
      "\n",
      "                    4          5                      6                     7  \\\n",
      "0           gravity.x  gravity.y              gravity.z        rotationRate.x   \n",
      "1            0.741895   0.669768  -0.031672000000000006              0.316738   \n",
      "2            0.753099   0.657116              -0.032255              0.842032   \n",
      "3  0.7596109999999999   0.649555              -0.032707  -0.13814300000000002   \n",
      "4            0.760709   0.647788  -0.041139999999999996             -0.025005   \n",
      "\n",
      "                8                   9                   10  \\\n",
      "0  rotationRate.y      rotationRate.z   userAcceleration.x   \n",
      "1         0.77818  1.0827639999999998             0.294894   \n",
      "2        0.424446            0.643574  0.21940500000000002   \n",
      "3       -0.040741            0.343563             0.010714   \n",
      "4       -1.048717             0.03586            -0.008389   \n",
      "\n",
      "                     11                    12 label  \n",
      "0    userAcceleration.y    userAcceleration.z   dws  \n",
      "1  -0.18449300000000002              0.377542   dws  \n",
      "2  0.035845999999999996   0.11486600000000001   dws  \n",
      "3              0.134701  -0.16780799999999998   dws  \n",
      "4   0.13678800000000002              0.094958   dws  \n",
      "label\n",
      "wlk    344360\n",
      "sit    338826\n",
      "std    306475\n",
      "ups    157357\n",
      "jog    134279\n",
      "dws    131928\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "base_path = r\"C:\\Users\\Hp\\Downloads\\archive (1)\\A_DeviceMotion_data\\A_DeviceMotion_data\"\n",
    "\n",
    "folders = ['dws_1', 'dws_11', 'dws_2', 'jog_16', 'jog_9', 'sit_13', 'sit_5', \n",
    "           'std_14', 'std_6', 'ups_12', 'ups_3', 'ups_4', 'wlk_15', 'wlk_7', 'wlk_8']\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(base_path, folder)\n",
    "    \n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".csv\") or file.endswith(\".txt\"):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            df = pd.read_csv(file_path, header=None)\n",
    "            df['label'] = folder[:3]  \n",
    "            all_data.append(df)\n",
    "\n",
    "df_all = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "print(df_all.head())\n",
    "print(df_all['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c758e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   time  attitude.roll  attitude.pitch  attitude.yaw  gravity.x  gravity.y  \\\n",
      "0     0       1.528132       -0.733896      0.696372   0.741895   0.669768   \n",
      "1     1       1.527992       -0.716987      0.677762   0.753099   0.657116   \n",
      "2     2       1.527765       -0.706999      0.670951   0.759611   0.649555   \n",
      "3     3       1.516768       -0.704678      0.675735   0.760709   0.647788   \n",
      "4     4       1.493941       -0.703918      0.672994   0.760062   0.647210   \n",
      "\n",
      "   gravity.z  rotationRate.x  rotationRate.y  rotationRate.z  \\\n",
      "0  -0.031672        0.316738        0.778180        1.082764   \n",
      "1  -0.032255        0.842032        0.424446        0.643574   \n",
      "2  -0.032707       -0.138143       -0.040741        0.343563   \n",
      "3  -0.041140       -0.025005       -1.048717        0.035860   \n",
      "4  -0.058530        0.114253       -0.912890        0.047341   \n",
      "\n",
      "   userAcceleration.x  userAcceleration.y  userAcceleration.z label  \n",
      "0            0.294894           -0.184493            0.377542   dws  \n",
      "1            0.219405            0.035846            0.114866   dws  \n",
      "2            0.010714            0.134701           -0.167808   dws  \n",
      "3           -0.008389            0.136788            0.094958   dws  \n",
      "4            0.199441            0.353996           -0.044299   dws  \n",
      "label\n",
      "wlk    344288\n",
      "sit    338778\n",
      "std    306427\n",
      "ups    157285\n",
      "jog    134231\n",
      "dws    131856\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "base_path = r\"C:\\Users\\Hp\\Downloads\\archive (1)\\A_DeviceMotion_data\\A_DeviceMotion_data\"\n",
    "\n",
    "folders = ['dws_1', 'dws_11', 'dws_2', 'jog_16', 'jog_9', 'sit_13', 'sit_5', \n",
    "           'std_14', 'std_6', 'ups_12', 'ups_3', 'ups_4', 'wlk_15', 'wlk_7', 'wlk_8']\n",
    "\n",
    "columns = [\n",
    "    \"time\", \"attitude.roll\", \"attitude.pitch\", \"attitude.yaw\",\n",
    "    \"gravity.x\", \"gravity.y\", \"gravity.z\",\n",
    "    \"rotationRate.x\", \"rotationRate.y\", \"rotationRate.z\",\n",
    "    \"userAcceleration.x\", \"userAcceleration.y\", \"userAcceleration.z\"\n",
    "]\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(base_path, folder)\n",
    "    \n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".csv\") or file.endswith(\".txt\"):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            df = pd.read_csv(file_path, skiprows=1, header=None, names=columns)\n",
    "            df['label'] = folder[:3]\n",
    "            all_data.append(df)\n",
    "\n",
    "df_all = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "print(df_all.head())\n",
    "print(df_all['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5c0aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1516  160    2    7  264  656]\n",
      " [ 127 2151    2    0   65  330]\n",
      " [   0    0 6721    0    6    3]\n",
      " [  19    0    0 6063   36   12]\n",
      " [ 205   93    2   21 2115  769]\n",
      " [ 140  119    0   13  228 6413]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dws       0.76      0.58      0.66      2605\n",
      "         jog       0.85      0.80      0.83      2675\n",
      "         sit       1.00      1.00      1.00      6730\n",
      "         std       0.99      0.99      0.99      6130\n",
      "         ups       0.78      0.66      0.71      3205\n",
      "         wlk       0.78      0.93      0.85      6913\n",
      "\n",
      "    accuracy                           0.88     28258\n",
      "   macro avg       0.86      0.83      0.84     28258\n",
      "weighted avg       0.88      0.88      0.88     28258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_all['label_encoded'] = le.fit_transform(df_all['label'])\n",
    "\n",
    "\n",
    "sample_df = df_all.sample(frac=0.1, random_state=42)\n",
    "\n",
    "X = sample_df.drop(columns=['label', 'label_encoded', 'time'])\n",
    "y = sample_df['label_encoded']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba2b225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "عدد الميزات بعد PCA: 10\n",
      "Confusion Matrix:\n",
      "[[1314  165    0   32  301  793]\n",
      " [ 113 2139    0    0   64  359]\n",
      " [   0    0 6717    0    8    5]\n",
      " [  16    0    0 6063   39   12]\n",
      " [ 207  117    4   57 1940  880]\n",
      " [ 144  136    0   22  242 6369]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dws       0.73      0.50      0.60      2605\n",
      "         jog       0.84      0.80      0.82      2675\n",
      "         sit       1.00      1.00      1.00      6730\n",
      "         std       0.98      0.99      0.99      6130\n",
      "         ups       0.75      0.61      0.67      3205\n",
      "         wlk       0.76      0.92      0.83      6913\n",
      "\n",
      "    accuracy                           0.87     28258\n",
      "   macro avg       0.84      0.80      0.82     28258\n",
      "weighted avg       0.87      0.87      0.86     28258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_all['label_encoded'] = le.fit_transform(df_all['label'])\n",
    "\n",
    "\n",
    "sample_df = df_all.sample(frac=0.1, random_state=42)\n",
    "\n",
    "X = sample_df.drop(columns=['label', 'label_encoded', 'time'])\n",
    "y = sample_df['label_encoded']\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(f\"عدد الميزات بعد PCA: {X_pca.shape[1]}\")  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_pca, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3a3cb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (3.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from xgboost) (2.1.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from xgboost) (1.15.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\Hp\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08b1aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "عدد الميزات بعد PCA: 10\n",
      "Confusion Matrix:\n",
      "[[1174  169    1   38  377  846]\n",
      " [ 130 2007    0    0   77  461]\n",
      " [   0    0 6721    0    5    4]\n",
      " [  19    0    0 6070   29   12]\n",
      " [ 244  110    1   64 1837  949]\n",
      " [ 292  188    0   25  394 6014]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dws       0.63      0.45      0.53      2605\n",
      "         jog       0.81      0.75      0.78      2675\n",
      "         sit       1.00      1.00      1.00      6730\n",
      "         std       0.98      0.99      0.98      6130\n",
      "         ups       0.68      0.57      0.62      3205\n",
      "         wlk       0.73      0.87      0.79      6913\n",
      "\n",
      "    accuracy                           0.84     28258\n",
      "   macro avg       0.80      0.77      0.78     28258\n",
      "weighted avg       0.84      0.84      0.84     28258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_all['label_encoded'] = le.fit_transform(df_all['label'])\n",
    "\n",
    "\n",
    "sample_df = df_all.sample(frac=0.1, random_state=42)\n",
    "\n",
    "X = sample_df.drop(columns=['label', 'label_encoded', 'time'])\n",
    "y = sample_df['label_encoded']\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(f\"عدد الميزات بعد PCA: {X_pca.shape[1]}\")\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_pca, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "\n",
    "params = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': len(le.classes_),\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'seed': 42,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "\n",
    "num_rounds = 100\n",
    "model = xgb.train(params, dtrain, num_boost_round=num_rounds)\n",
    "\n",
    "\n",
    "y_pred = model.predict(dtest)\n",
    "\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc398792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1428  150    2   11  322  692]\n",
      " [ 132 2114    2    0   76  351]\n",
      " [   1    1 6722    0    5    1]\n",
      " [  13    0    0 6073   33   11]\n",
      " [ 251   99    0   29 1990  836]\n",
      " [ 251  151    0   17  356 6138]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dws       0.69      0.55      0.61      2605\n",
      "         jog       0.84      0.79      0.81      2675\n",
      "         sit       1.00      1.00      1.00      6730\n",
      "         std       0.99      0.99      0.99      6130\n",
      "         ups       0.72      0.62      0.66      3205\n",
      "         wlk       0.76      0.89      0.82      6913\n",
      "\n",
      "    accuracy                           0.87     28258\n",
      "   macro avg       0.83      0.81      0.82     28258\n",
      "weighted avg       0.86      0.87      0.86     28258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_all['label_encoded'] = le.fit_transform(df_all['label'])\n",
    "\n",
    "sample_df = df_all.sample(frac=0.1, random_state=42)\n",
    "\n",
    "X = sample_df.drop(columns=['label', 'label_encoded', 'time'])\n",
    "y = sample_df['label_encoded']\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': len(le.classes_),\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'seed': 42,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "\n",
    "num_rounds = 100\n",
    "model = xgb.train(params, dtrain, num_boost_round=num_rounds)\n",
    "\n",
    "\n",
    "y_pred = model.predict(dtest)\n",
    "\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457344c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [23:42:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "أفضل معلمات بعد البحث:\n",
      "{'subsample': 0.8, 'n_estimators': 150, 'max_depth': 9, 'learning_rate': 0.2, 'gamma': 0, 'colsample_bytree': 0.8}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1653  127    2    8  303  512]\n",
      " [ 115 2244    1    0   80  235]\n",
      " [   0    0 6720    0    6    4]\n",
      " [  19    0    0 6074   27   10]\n",
      " [ 241   99    0   25 2237  603]\n",
      " [ 193  109    0   15  284 6312]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dws       0.74      0.63      0.69      2605\n",
      "         jog       0.87      0.84      0.85      2675\n",
      "         sit       1.00      1.00      1.00      6730\n",
      "         std       0.99      0.99      0.99      6130\n",
      "         ups       0.76      0.70      0.73      3205\n",
      "         wlk       0.82      0.91      0.87      6913\n",
      "\n",
      "    accuracy                           0.89     28258\n",
      "   macro avg       0.87      0.85      0.85     28258\n",
      "weighted avg       0.89      0.89      0.89     28258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_all['label_encoded'] = le.fit_transform(df_all['label'])\n",
    "\n",
    "sample_df = df_all.sample(frac=0.1, random_state=42)\n",
    "\n",
    "X = sample_df.drop(columns=['label', 'label_encoded', 'time'])\n",
    "y = sample_df['label_encoded']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(le.classes_), use_label_encoder=False, eval_metric='mlogloss', verbosity=1, seed=42)\n",
    "\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.3, 0.5]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    scoring='accuracy',\n",
    "    cv=3, \n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"أفضل معلمات بعد البحث:\")\n",
    "print(random_search.best_params_)\n",
    "\n",
    "\n",
    "y_pred = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5581c839",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m15895/15895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 10ms/step - accuracy: 0.9312 - loss: 0.2142 - val_accuracy: 0.9792 - val_loss: 0.0722\n",
      "Epoch 2/10\n",
      "\u001b[1m15895/15895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 10ms/step - accuracy: 0.9802 - loss: 0.0706 - val_accuracy: 0.9842 - val_loss: 0.0534\n",
      "Epoch 3/10\n",
      "\u001b[1m15895/15895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 10ms/step - accuracy: 0.9840 - loss: 0.0544 - val_accuracy: 0.9863 - val_loss: 0.0447\n",
      "Epoch 4/10\n",
      "\u001b[1m15895/15895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 10ms/step - accuracy: 0.9863 - loss: 0.0455 - val_accuracy: 0.9879 - val_loss: 0.0388\n",
      "Epoch 5/10\n",
      "\u001b[1m15895/15895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 10ms/step - accuracy: 0.9882 - loss: 0.0393 - val_accuracy: 0.9887 - val_loss: 0.0360\n",
      "Epoch 6/10\n",
      "\u001b[1m15895/15895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 10ms/step - accuracy: 0.9891 - loss: 0.0354 - val_accuracy: 0.9907 - val_loss: 0.0294\n",
      "Epoch 7/10\n",
      "\u001b[1m15895/15895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 10ms/step - accuracy: 0.9903 - loss: 0.0313 - val_accuracy: 0.9901 - val_loss: 0.0314\n",
      "Epoch 8/10\n",
      "\u001b[1m15895/15895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 10ms/step - accuracy: 0.9910 - loss: 0.0287 - val_accuracy: 0.9921 - val_loss: 0.0251\n",
      "Epoch 9/10\n",
      "\u001b[1m15895/15895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 11ms/step - accuracy: 0.9918 - loss: 0.0266 - val_accuracy: 0.9928 - val_loss: 0.0236\n",
      "Epoch 10/10\n",
      "\u001b[1m15895/15895\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 11ms/step - accuracy: 0.9923 - loss: 0.0247 - val_accuracy: 0.9931 - val_loss: 0.0215\n",
      "\u001b[1m8831/8831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - accuracy: 0.9935 - loss: 0.0206\n",
      "Test accuracy: 0.9935\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_all['label_encoded'] = le.fit_transform(df_all['label'])\n",
    "\n",
    "\n",
    "X = df_all.drop(columns=['label', 'label_encoded', 'time']).values\n",
    "y = df_all['label_encoded'].values\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "sequence_length = 20\n",
    "\n",
    "def create_sequences(X, y, seq_length):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i:i+seq_length])\n",
    "        y_seq.append(y[i+seq_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "X_seq, y_seq = create_sequences(X_scaled, y, sequence_length)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42, stratify=y_seq)\n",
    "\n",
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(sequence_length, X.shape[1]), return_sequences=False))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(len(le.classes_), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train_cat, epochs=10, batch_size=64, validation_split=0.1)\n",
    "\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test_cat)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86521351",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"final_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7de45b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
